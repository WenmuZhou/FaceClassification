model_name: MiniXception    # Don't need to modify this item, because this configuration file is just for this model.
in_channels: 1
n_classes: 2

batch_size: 32
epochs: 1000
validation_split: .2


seed: 666

model_dir: ./models/mini  # Where to save the model parameters
just_keep_the_best: True

restore: False  # If `True`, restore parameters from `model_state_dict` and `opt_state_dict` for training
model_state_dict: ./models/mini/MiniXception-93-0.9605474179152765.params  # Where to restore the model parameters
opt_state_dict: ./models/mini/MiniXception-93.opt    # Where to restore the optimizer parameters

dataset:
  imdb_dir: /data1/lihp/data/imdb_crop/   # Where is the `imdb` dataset
  img_size: 64
  grayscale: True
  do_rand_crop: True
  translation_factor: .2
  vertical_flip_probability: 0.
  read_img_at_once: False  # Set to `True` if the memory of your device allows. It will speed up the training.

num_workers: 4  # num_workers of data loader

logdir: ./log/mini   # Where to output the logs
